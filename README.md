# Case QuantumFinance â€“ Classificador de Chamados (Disciplina NLP)

## ğŸ“Œ Contexto do Projeto

A **QuantumFinance**, empresa do setor financeiro digital, mantÃ©m um canal de atendimento via chat onde os clientes relatam dÃºvidas, solicitaÃ§Ãµes e problemas.

O desafio Ã© desenvolver um **modelo de inteligÃªncia artificial** capaz de **classificar automaticamente o assunto dos chamados** com base no texto livre fornecido pelo cliente, com o objetivo de:

* Otimizar o direcionamento das demandas.
* Reduzir tempo de atendimento.
* Aumentar a eficiÃªncia operacional.

## ğŸ¯ Objetivos

* Desenvolver um **sistema de classificaÃ§Ã£o de chamados** com tÃ©cnicas de **Processamento de Linguagem Natural (PLN)**.
* Implementar e comparar **duas abordagens principais**:

  1. **TF-IDF + Modelos clÃ¡ssicos de Machine Learning**.
  2. **Embeddings (Word2Vec/BERTimbau) + Classificadores supervisionados**.
* Atingir **F1-Score â‰¥ 75%** no conjunto de teste.

## âš™ï¸ Requisitos TÃ©cnicos

* PrÃ©-processamento textual (limpeza, normalizaÃ§Ã£o, lematizaÃ§Ã£o).
* VetorizaÃ§Ã£o com **n-gramas + TF-IDF**.
* ExtraÃ§Ã£o de embeddings com **BERTimbau**.
* ImplementaÃ§Ã£o de pelo menos **dois pipelines completos**:

  * **Modelo tradicional (TF-IDF + ML)**.
  * **Modelo com embeddings + ML**.
* AvaliaÃ§Ã£o com **F1-Score (weighted)**.

## ğŸ“Š AnÃ¡lises e Experimentos

### ğŸ”¹ SeleÃ§Ã£o de HiperparÃ¢metros (TF-IDF)

Testamos diferentes tamanhos de vocabulÃ¡rio no **TF-IDF** para identificar o melhor trade-off entre dimensionalidade e performance.

![TF-IDF Score](https://github.com/RafaelGallo/FIAP_NLP_Quantum_Finance/blob/main/img/01.png?raw=true)

### ğŸ”¹ AvaliaÃ§Ã£o de Modelos ClÃ¡ssicos (TF-IDF)

| Modelo                 | Accuracy  | Precision | Recall    | F1-Score  |
| ---------------------- | --------- | --------- | --------- | --------- |
| DecisionTreeClassifier | 0.628     | 0.633     | 0.628     | 0.626     |
| RandomForestClassifier | 0.795     | 0.795     | 0.795     | 0.794     |
| LogisticRegression     | **0.891** | **0.892** | **0.891** | **0.891** |
| AdaBoostClassifier     | 0.800     | 0.799     | 0.800     | 0.799     |
| XGBClassifier          | 0.315     | 0.381     | 0.315     | 0.235     |
| LGBMClassifier         | 0.886     | 0.886     | 0.886     | 0.886     |

ğŸ”‘ **ConclusÃ£o**:

* **Logistic Regression (TF-IDF)** foi o **melhor modelo** com F1 = **0.891**.
* **LightGBM (TF-IDF)** apresentou desempenho muito prÃ³ximo.
* **RandomForest** e **AdaBoost** foram alternativas estÃ¡veis (~0.79 F1).
* **XGBoost** teve desempenho insatisfatÃ³rio (F1 = 0.23).

### ğŸ”¹ Matrizes de ConfusÃ£o (TF-IDF e Transformers)

* **Logistic Regression (TF-IDF)**
  ![ConfusÃ£o LR](https://github.com/RafaelGallo/FIAP_NLP_Quantum_Finance/blob/main/img/35.png?raw=true)

### ğŸ”¹ Curvas ROC Multiclasse

* **Logistic Regression (TF-IDF)**
  ![ROC LR](https://github.com/RafaelGallo/FIAP_NLP_Quantum_Finance/blob/main/img/36.png?raw=true)

* **BERTimbau + ML (RandomForest, AdaBoost, LogisticRegression)**
  ![ROC BERT](https://github.com/RafaelGallo/FIAP_NLP_Quantum_Finance/blob/main/img/05.png?raw=true)

Boa, Rafael ğŸ‘
Essa imagem Ã© essencial para explicar a base teÃ³rica do projeto (Transformers â†’ BERTimbau). O ideal Ã© incluir no README uma seÃ§Ã£o dedicada Ã  **Arquitetura Transformer**, contextualizando o uso do encoder e a diferenÃ§a em relaÃ§Ã£o ao modelo seq2seq tradicional.

## ğŸ—ï¸ Arquitetura Transformer

O modelo **Transformer** (Vaswani et al., 2017) Ã© a base para arquiteturas modernas de PLN, incluindo o **BERTimbau** utilizado neste projeto.

Ele Ã© composto por duas partes principais:

* **Encoder**: responsÃ¡vel por processar o texto de entrada e gerar representaÃ§Ãµes contextuais (embeddings enriquecidos).
* **Decoder**: usado em tarefas de geraÃ§Ã£o de texto (nÃ£o utilizado no BERT, que emprega apenas a parte Encoder).

O mecanismo central Ã© o **Self-Attention**, que permite ao modelo capturar dependÃªncias de longo alcance entre palavras em uma frase.

![Arquitetura Transformer](https://github.com/RafaelGallo/FIAP_NLP_Quantum_Finance/blob/main/img/03.png?raw=true)

ğŸ”‘ **Resumo aplicado ao projeto**:

* Utilizamos o **Encoder do BERTimbau** para gerar embeddings em portuguÃªs.
* Esses embeddings foram usados diretamente em classificadores supervisionados (Logistic Regression, RandomForest, AdaBoost etc.).
* O uso do Transformer permitiu capturar **relaÃ§Ãµes semÃ¢nticas contextuais** entre termos dos chamados, indo alÃ©m da simples contagem de palavras (TF-IDF).

## ğŸ§© Transformers â€“ BERTimbau

Utilizamos o modelo **BERTimbau (NeuralMind)**, prÃ©-treinado para portuguÃªs.
Dois cenÃ¡rios foram testados:

1. **Fine-tuning direto (classificaÃ§Ã£o supervisionada)**.
2. **ExtraÃ§Ã£o de embeddings** para alimentar classificadores como Logistic Regression, Random Forest, AdaBoost, etc.

Apesar da riqueza semÃ¢ntica dos embeddings, os resultados **nÃ£o superaram o TF-IDF** neste problema especÃ­fico.

## ğŸ“‰ ComparaÃ§Ã£o Final â€“ TF-IDF vs Embeddings

| Modelo                            | F1-Score  |
| --------------------------------- | --------- |
| LogisticRegression (TF-IDF)       | **0.891** |
| LightGBM (TF-IDF)                 | 0.886     |
| RandomForest (TF-IDF)             | 0.794     |
| AdaBoost (TF-IDF)                 | 0.799     |
| LogisticRegression (Transformers) | 0.738     |
| XGBoost (Transformers)            | 0.701     |
| LGBM (Transformers)               | 0.684     |
| DecisionTree (Transformers)       | 0.415     |

âœ… **TF-IDF + Logistic Regression continua sendo a melhor abordagem neste cenÃ¡rio.**

## ğŸš¨ Leakage (Vazamento de Dados)

* Investigamos potenciais **colunas derivadas incorretamente do target**.
* Foram removidas features que poderiam causar **vazamento de informaÃ§Ã£o** (ex: colunas calculadas antes do `train_test_split`).
* Isso garantiu que o modelo sÃ³ tivesse acesso a variÃ¡veis **disponÃ­veis em produÃ§Ã£o**.

## ğŸ”® ConclusÃµes Finais

1. **Modelos clÃ¡ssicos com TF-IDF superaram embeddings BERT** neste caso.
2. **Logistic Regression (TF-IDF)** foi o **modelo campeÃ£o**, atingindo F1-Score de **0.891**.
3. **LightGBM** Ã© uma Ã³tima alternativa, embora apresente sinais leves de overfitting.
4. Embeddings BERT + ML nÃ£o performaram tÃ£o bem sem fine-tuning completo.

## ğŸš€ PrÃ³ximos Passos

* Realizar **fine-tuning supervisionado completo do BERTimbau**.
* Testar **Sentence-BERT** e outros embeddings contextuais.
* Aplicar **Explainable AI (LIME/SHAP)** para entender melhor as decisÃµes dos modelos.
* Avaliar **pipelines de ensemble** (LR + LGBM).

## ğŸ“‚ Estrutura do RepositÃ³rio

```
â”œâ”€â”€ data/                   # Conjunto de dados (nÃ£o incluso no repositÃ³rio pÃºblico)
â”œâ”€â”€ img/                    # GrÃ¡ficos e matrizes de confusÃ£o
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ Template_Trabalho_Final_NLP.ipynb
â”‚   â””â”€â”€ Experimentos_Modelos.ipynb
â”œâ”€â”€ requirements.txt        # DependÃªncias do projeto
â””â”€â”€ README.md               # Este arquivo
```
