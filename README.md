# Case QuantumFinance ‚Äì Classificador de Chamados (Disciplina NLP)

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange?logo=jupyter)
![scikit-learn](https://img.shields.io/badge/Scikit--Learn-ML-yellow?logo=scikitlearn)
![Transformers](https://img.shields.io/badge/HuggingFace-Transformers-green?logo=huggingface)
![Pandas](https://img.shields.io/badge/Pandas-Data_Analysis-purple?logo=pandas)
![Matplotlib](https://img.shields.io/badge/Matplotlib-Visualization-blue?logo=plotly)
![Seaborn](https://img.shields.io/badge/Seaborn-Visualization-teal)
![FIAP](https://img.shields.io/badge/MBA-FIAP-red)
![Status](https://img.shields.io/badge/Projeto-Conclu√≠do-success)

![log](https://github.com/RafaelGallo/FIAP_NLP_Quantum_Finance/blob/main/img/Log.png?raw=true)


## üìå Contexto do Projeto

A **QuantumFinance**, empresa do setor financeiro digital, mant√©m um canal de atendimento via chat onde os clientes relatam d√∫vidas, solicita√ß√µes e problemas.

O desafio √© desenvolver um **modelo de intelig√™ncia artificial** capaz de **classificar automaticamente o assunto dos chamados** com base no texto livre fornecido pelo cliente, com o objetivo de:

* Otimizar o direcionamento das demandas.
* Reduzir tempo de atendimento.
* Aumentar a efici√™ncia operacional.

## üéØ Objetivos

* Desenvolver um **sistema de classifica√ß√£o de chamados** com t√©cnicas de **Processamento de Linguagem Natural (PLN)**.
* Implementar e comparar **duas abordagens principais**:

  1. **TF-IDF + Modelos cl√°ssicos de Machine Learning**.
  2. **Embeddings (Word2Vec/BERTimbau) + Classificadores supervisionados**.
* Atingir **F1-Score ‚â• 75%** no conjunto de teste.

## ‚öôÔ∏è Requisitos T√©cnicos

* Pr√©-processamento textual (limpeza, normaliza√ß√£o, lematiza√ß√£o).
* Vetoriza√ß√£o com **n-gramas + TF-IDF**.
* Extra√ß√£o de embeddings com **BERTimbau**.
* Implementa√ß√£o de pelo menos **dois pipelines completos**:

  * **Modelo tradicional (TF-IDF + ML)**.
  * **Modelo com embeddings + ML**.
* Avalia√ß√£o com **F1-Score (weighted)**.

## üìä An√°lises e Experimentos

### üîπ Sele√ß√£o de Hiperpar√¢metros (TF-IDF)

Testamos diferentes tamanhos de vocabul√°rio no **TF-IDF** para identificar o melhor trade-off entre dimensionalidade e performance.

![TF-IDF Score](https://github.com/RafaelGallo/FIAP_NLP_Quantum_Finance/blob/main/img/01.png?raw=true)

### üîπ Avalia√ß√£o de Modelos Cl√°ssicos (TF-IDF)

| Modelo                 | Accuracy  | Precision | Recall    | F1-Score  |
| ---------------------- | --------- | --------- | --------- | --------- |
| DecisionTreeClassifier | 0.628     | 0.633     | 0.628     | 0.626     |
| RandomForestClassifier | 0.795     | 0.795     | 0.795     | 0.794     |
| LogisticRegression     | **0.891** | **0.892** | **0.891** | **0.891** |
| AdaBoostClassifier     | 0.800     | 0.799     | 0.800     | 0.799     |
| XGBClassifier          | 0.315     | 0.381     | 0.315     | 0.235     |
| LGBMClassifier         | 0.886     | 0.886     | 0.886     | 0.886     |

üîë **Conclus√£o**:

* **Logistic Regression (TF-IDF)** foi o **melhor modelo** com F1 = **0.891**.
* **LightGBM (TF-IDF)** apresentou desempenho muito pr√≥ximo.
* **RandomForest** e **AdaBoost** foram alternativas est√°veis (~0.79 F1).
* **XGBoost** teve desempenho insatisfat√≥rio (F1 = 0.23).

### üîπ Matrizes de Confus√£o (TF-IDF e Transformers)

* **Logistic Regression (TF-IDF)**
  ![Confus√£o LR](https://github.com/RafaelGallo/FIAP_NLP_Quantum_Finance/blob/main/img/35.png?raw=true)

### üîπ Curvas ROC Multiclasse

* **Logistic Regression (TF-IDF)**
  ![ROC LR](https://github.com/RafaelGallo/FIAP_NLP_Quantum_Finance/blob/main/img/36.png?raw=true)

* **BERTimbau + ML (RandomForest, AdaBoost, LogisticRegression)**
  ![ROC BERT](https://github.com/RafaelGallo/FIAP_NLP_Quantum_Finance/blob/main/img/05.png?raw=true)

## üèóÔ∏è Arquitetura Transformer

O modelo **Transformer** (Vaswani et al., 2017) √© a base para arquiteturas modernas de PLN, incluindo o **BERTimbau** utilizado neste projeto.

Ele √© composto por duas partes principais:

* **Encoder**: respons√°vel por processar o texto de entrada e gerar representa√ß√µes contextuais (embeddings enriquecidos).
* **Decoder**: usado em tarefas de gera√ß√£o de texto (n√£o utilizado no BERT, que emprega apenas a parte Encoder).

O mecanismo central √© o **Self-Attention**, que permite ao modelo capturar depend√™ncias de longo alcance entre palavras em uma frase.

![Arquitetura Transformer](https://github.com/RafaelGallo/FIAP_NLP_Quantum_Finance/blob/main/img/03.png?raw=true)

üîë **Resumo aplicado ao projeto**:

* Utilizamos o **Encoder do BERTimbau** para gerar embeddings em portugu√™s.
* Esses embeddings foram usados diretamente em classificadores supervisionados (Logistic Regression, RandomForest, AdaBoost etc.).
* O uso do Transformer permitiu capturar **rela√ß√µes sem√¢nticas contextuais** entre termos dos chamados, indo al√©m da simples contagem de palavras (TF-IDF).

## üß© Transformers ‚Äì BERTimbau

Utilizamos o modelo **BERTimbau (NeuralMind)**, pr√©-treinado para portugu√™s.
Dois cen√°rios foram testados:

1. **Fine-tuning direto (classifica√ß√£o supervisionada)**.
2. **Extra√ß√£o de embeddings** para alimentar classificadores como Logistic Regression, Random Forest, AdaBoost, etc.

Apesar da riqueza sem√¢ntica dos embeddings, os resultados **n√£o superaram o TF-IDF** neste problema espec√≠fico.

## üìâ Compara√ß√£o Final ‚Äì TF-IDF vs Embeddings

| Modelo                            | F1-Score  |
| --------------------------------- | --------- |
| LogisticRegression (TF-IDF)       | **0.891** |
| LightGBM (TF-IDF)                 | 0.886     |
| RandomForest (TF-IDF)             | 0.794     |
| AdaBoost (TF-IDF)                 | 0.799     |
| LogisticRegression (Transformers) | 0.738     |
| XGBoost (Transformers)            | 0.701     |
| LGBM (Transformers)               | 0.684     |
| DecisionTree (Transformers)       | 0.415     |

‚úÖ **TF-IDF + Logistic Regression continua sendo a melhor abordagem neste cen√°rio.**

## üö® Leakage (Vazamento de Dados)

* Investigamos potenciais **colunas derivadas incorretamente do target**.
* Foram removidas features que poderiam causar **vazamento de informa√ß√£o** (ex: colunas calculadas antes do `train_test_split`).
* Isso garantiu que o modelo s√≥ tivesse acesso a vari√°veis **dispon√≠veis em produ√ß√£o**.

## üîÆ Conclus√µes Finais

1. **Modelos cl√°ssicos com TF-IDF superaram embeddings BERT** neste caso.
2. **Logistic Regression (TF-IDF)** foi o **modelo campe√£o**, atingindo F1-Score de **0.891**.
3. **LightGBM** √© uma √≥tima alternativa, embora apresente sinais leves de overfitting.
4. Embeddings BERT + ML n√£o performaram t√£o bem sem fine-tuning completo.

## üöÄ Pr√≥ximos Passos

* Realizar **fine-tuning supervisionado completo do BERTimbau**.
* Testar **Sentence-BERT** e outros embeddings contextuais.
* Aplicar **Explainable AI (LIME/SHAP)** para entender melhor as decis√µes dos modelos.
* Avaliar **pipelines de ensemble** (LR + LGBM).

## üìÇ Estrutura do Reposit√≥rio

```
‚îú‚îÄ‚îÄ data/                   # Conjunto de dados (n√£o incluso no reposit√≥rio p√∫blico)
‚îú‚îÄ‚îÄ img/                    # Gr√°ficos e matrizes de confus√£o
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ Template_Trabalho_Final_NLP.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ Experimentos_Modelos.ipynb
‚îú‚îÄ‚îÄ requirements.txt        # Depend√™ncias do projeto
‚îî‚îÄ‚îÄ README.md               # Este arquivo
```
